{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from hyperopt import hp, fmin, tpe\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "random.seed(499)\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "##################################### functions which are used for preprocessing #######################################\n",
    "\n",
    "\n",
    "def impute(df, by, method='mean'):\n",
    "    if method == 'mean':\n",
    "        return df.fillna(by.mean())\n",
    "    elif method == 'median':\n",
    "        return df.fillna(by.median())\n",
    "    else:\n",
    "        raise ValueError(\"Imputation method not allowed!\\n - Please choose from ['mean','median']\")\n",
    "\n",
    "\n",
    "def load_files(dir_name):\n",
    "    dfs = []\n",
    "    for file in os.listdir(dir_name):\n",
    "        dfs.append(pd.read_csv(dir_name + file))\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def long2wide(dfs, col, value, index=None):\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i].pivot(index=index, columns=col, values=value)\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def feature_extract(dfs, static_col):\n",
    "    mean = pd.DataFrame()\n",
    "    maximum = pd.DataFrame()\n",
    "    minimum = pd.DataFrame()\n",
    "\n",
    "    for df in dfs:\n",
    "        mean = mean.append(df.mean(), ignore_index=True)\n",
    "        maximum = maximum.append(df.max(), ignore_index=True)\n",
    "        minimum = minimum.append(df.min(), ignore_index=True)\n",
    "\n",
    "    static = mean[static_col]\n",
    "    mean = mean.drop(static_col, axis=1).add_suffix('_mean')\n",
    "    maximum = maximum.drop(static_col, axis=1).add_suffix('_max')\n",
    "    minimum = minimum.drop(static_col, axis=1).add_suffix('_min')\n",
    "    return pd.concat([static, mean, maximum, minimum], axis=1, sort=False)\n",
    "\n",
    "\n",
    "def non0var(df):\n",
    "    categorical = df.select_dtypes(include='object')\n",
    "    numerical = df.select_dtypes(exclude='object')\n",
    "    numerical = numerical.iloc[:, list(numerical.var() != 0)]\n",
    "    df = pd.concat([categorical, numerical], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def synchronize(train, validation, test):\n",
    "    test = test.drop(list(set(test).difference(set(train))), axis=1)\n",
    "    test = test.drop(list(set(test).difference(set(validation))), axis=1)\n",
    "    validation = validation.drop(list(set(validation).difference(set(train))), axis=1)\n",
    "    validation = validation.drop(list(set(validation).difference(set(test))), axis=1)\n",
    "    train = train.drop(list(set(train).difference(set(test))), axis=1)\n",
    "    train = train.drop(list(set(train).difference(set(validation))), axis=1)\n",
    "    return train, validation, test\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "###################################### functions which are used for modelling ##########################################\n",
    "\n",
    "\n",
    "def objective(params):\n",
    "    bst = xgb.XGBClassifier(max_depth=int(params['max_depth']),learning_rate=params['learning_rate'],\n",
    "                                n_estimators=int(params['n_estimators']),gamma=params['gamma'],\n",
    "                                min_child_weight=params['min_child_weight'],max_delta_step=params['max_delta_step'],\n",
    "                                subsample=params['subsample'],\n",
    "                                reg_alpha=params['reg_alpha'],reg_lambda=params['reg_lambda'],\n",
    "                                scale_pos_weight=params['scale_pos_weight'])\n",
    "    bst.fit(train_X,train_y)\n",
    "    yhat = bst.predict(validation_X)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(validation_y, yhat).ravel()\n",
    "    return 1-min(tp/(tp+fn),tp/(tp+fp))\n",
    "\n",
    "\n",
    "def model_evaluation(model):\n",
    "    model.fit(train_X, train_y)\n",
    "    yhat = model.predict(test_X)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(test_y, yhat).ravel()\n",
    "    return min(tp / (tp + fn), tp / (tp + fp)), model\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "######################################### high-level functions for the project #########################################\n",
    "\n",
    "\n",
    "def default_preprocess(dir_name):\n",
    "    dfs = load_files(dir_name)\n",
    "    dfs = long2wide(dfs, 'Parameter', 'Value')\n",
    "    df = feature_extract(dfs, ['RecordID', 'Gender', 'Age', 'Height', 'ICUType'])\n",
    "    df = df.replace(-1, np.NaN)\n",
    "    return df\n",
    "\n",
    "\n",
    "def default_modelling(space, objective, max_evals):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    param = fmin(objective, space, algo=tpe.suggest, max_evals=max_evals, rstate=np.random.RandomState(499))\n",
    "    df = open('param.txt','w')\n",
    "    df.write(str(param))\n",
    "    df.close()\n",
    "\n",
    "    model = xgb.XGBClassifier(max_depth=int(param['max_depth']), learning_rate=param['learning_rate'],\n",
    "                            n_estimators=int(param['n_estimators']), gamma=param['gamma'],\n",
    "                            min_child_weight=param['min_child_weight'], max_delta_step=param['max_delta_step'],\n",
    "                            subsample=param['subsample'], reg_alpha=param['reg_alpha'], reg_lambda=param['reg_lambda'],\n",
    "                            scale_pos_weight=param['scale_pos_weight'])\n",
    "    score1, model = model_evaluation(model)\n",
    "    return score1, model\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "##################################### functions for explainer ##########################################################\n",
    "\n",
    "\n",
    "def construct_explainer(model, test_X):\n",
    "    shap.initjs()\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(test_X)\n",
    "    return explainer, shap_values\n",
    "    \n",
    "def summary(shap_values, test_X):\n",
    "    shap.summary_plot(shap_values, test_X)\n",
    "    \n",
    "def effect(feature_name, shap_values, test_X):\n",
    "    shap.dependence_plot(feature_name, shap_values, test_X, interaction_index=None)\n",
    "    \n",
    "\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "######################################## main function of the project ##################################################\n",
    "\n",
    "\n",
    "train_X = default_preprocess('set-a/')\n",
    "train_X = impute(non0var(train_X), train_X)\n",
    "print('Training set ready to use!')\n",
    "validation_X = default_preprocess('set-b/')\n",
    "validation_X = impute(non0var(validation_X), validation_X)\n",
    "print('Validation set ready to use!')\n",
    "test_X = default_preprocess('set-c/')\n",
    "test_X = impute(non0var(test_X), train_X)\n",
    "print('test set ready to use!')\n",
    "train_X, validation_X, test_X = synchronize(train_X, validation_X, test_X)\n",
    "print('Datasets sychronized!')\n",
    "\n",
    "train_y = pd.read_csv('Outcomes-a.txt')[['RecordID', 'In-hospital_death']]\n",
    "validation_y = pd.read_csv('Outcomes-b.txt')[['RecordID', 'In-hospital_death']]\n",
    "test_y = pd.read_csv('Outcomes-c.txt')[['RecordID', 'In-hospital_death']]\n",
    "\n",
    "train = pd.merge(train_X, train_y, on='RecordID')\n",
    "validation = pd.merge(validation_X, validation_y, on='RecordID')\n",
    "test = pd.merge(test_X, test_y, on='RecordID')\n",
    "\n",
    "test_X = test.drop(['In-hospital_death','RecordID'],axis=1)\n",
    "test_X = test_X.reindex(sorted(test_X),axis=1)\n",
    "train_X = train.drop(['In-hospital_death','RecordID'], axis=1)\n",
    "train_X = train_X.reindex(sorted(train_X),axis=1)\n",
    "validation_X = validation.drop(['In-hospital_death','RecordID'], axis=1)\n",
    "validation_X = validation_X.reindex(sorted(validation_X),axis=1)\n",
    "test_y = test['In-hospital_death']\n",
    "train_y = train['In-hospital_death']\n",
    "validation_y = validation['In-hospital_death']\n",
    "\n",
    "space = {'max_depth': hp.quniform('max_depth', 2, 5, 1),\n",
    "         'learning_rate': hp.uniform('learning_rate', 0.01, 0.1),\n",
    "         'n_estimators': hp.quniform('n_estimators', 80, 150, 1),\n",
    "         'gamma': hp.uniform('gamma', 0, 10),\n",
    "         'min_child_weight': hp.uniform('min_child_weight', 0, 5),\n",
    "         'max_delta_step': hp.uniform('max_delta_step', 0, 10),\n",
    "         'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "         'reg_alpha': hp.uniform('reg_alpha', 0, 10),\n",
    "         'reg_lambda': hp.uniform('reg_lambda', 0, 10),\n",
    "         'scale_pos_weight': hp.uniform('scale_pos_weight', 3, 5)\n",
    "         }\n",
    "print('Model starts tuning!')\n",
    "score1,model = default_modelling(space, objective, 200)\n",
    "print(score1)\n",
    "\n",
    "explainer, shap_values = construct_explainer(model, test_X)\n",
    "summary(shap_values, test_X)\n",
    "effect('Age',shap_values, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='i7OMV538L6FVPWSP0B8GO'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"output value\"], \"baseValue\": -0.4731072783470154, \"outValue\": 0.07562899589538574, \"link\": \"identity\", \"featureNames\": [\"ALP_max\", \"ALP_mean\", \"ALP_min\", \"ALT_max\", \"ALT_mean\", \"ALT_min\", \"AST_max\", \"AST_mean\", \"AST_min\", \"Age\", \"Albumin_max\", \"Albumin_mean\", \"Albumin_min\", \"BUN_max\", \"BUN_mean\", \"BUN_min\", \"Bilirubin_max\", \"Bilirubin_mean\", \"Bilirubin_min\", \"Cholesterol_max\", \"Cholesterol_mean\", \"Cholesterol_min\", \"Creatinine_max\", \"Creatinine_mean\", \"Creatinine_min\", \"DiasABP_max\", \"DiasABP_mean\", \"DiasABP_min\", \"FiO2_max\", \"FiO2_mean\", \"FiO2_min\", \"GCS_max\", \"GCS_mean\", \"GCS_min\", \"Gender\", \"Glucose_max\", \"Glucose_mean\", \"Glucose_min\", \"HCO3_max\", \"HCO3_mean\", \"HCO3_min\", \"HCT_max\", \"HCT_mean\", \"HCT_min\", \"HR_max\", \"HR_mean\", \"HR_min\", \"Height\", \"ICUType\", \"K_max\", \"K_mean\", \"K_min\", \"Lactate_max\", \"Lactate_mean\", \"Lactate_min\", \"MAP_max\", \"MAP_mean\", \"MAP_min\", \"Mg_max\", \"Mg_mean\", \"Mg_min\", \"NIDiasABP_max\", \"NIDiasABP_mean\", \"NIDiasABP_min\", \"NIMAP_max\", \"NIMAP_mean\", \"NIMAP_min\", \"NISysABP_max\", \"NISysABP_mean\", \"NISysABP_min\", \"Na_max\", \"Na_mean\", \"Na_min\", \"PaCO2_max\", \"PaCO2_mean\", \"PaCO2_min\", \"PaO2_max\", \"PaO2_mean\", \"PaO2_min\", \"Platelets_max\", \"Platelets_mean\", \"Platelets_min\", \"RespRate_max\", \"RespRate_mean\", \"RespRate_min\", \"SaO2_max\", \"SaO2_mean\", \"SaO2_min\", \"SysABP_max\", \"SysABP_mean\", \"SysABP_min\", \"Temp_max\", \"Temp_mean\", \"Temp_min\", \"TroponinI_max\", \"TroponinI_mean\", \"TroponinI_min\", \"TroponinT_max\", \"TroponinT_mean\", \"TroponinT_min\", \"Urine_max\", \"Urine_mean\", \"Urine_min\", \"WBC_max\", \"WBC_mean\", \"WBC_min\", \"Weight_max\", \"Weight_mean\", \"Weight_min\", \"pH_max\", \"pH_mean\", \"pH_min\"], \"features\": {\"0\": {\"effect\": -0.006745882797986269, \"value\": 111.34437869822344}, \"1\": {\"effect\": 0.0006888192147016525, \"value\": 104.63411313045629}, \"2\": {\"effect\": 0.0017207900527864695, \"value\": 98.2946745562161}, \"3\": {\"effect\": -0.001530506182461977, \"value\": 222.42707728066324}, \"4\": {\"effect\": 0.0010634296340867877, \"value\": 171.74180914314266}, \"5\": {\"effect\": -0.008331798948347569, \"value\": 120.28936664730261}, \"6\": {\"effect\": -0.0024503832682967186, \"value\": 348.19999999998544}, \"7\": {\"effect\": -0.005331344436854124, \"value\": 240.46568885541976}, \"8\": {\"effect\": -0.001974075799807906, \"value\": 143.7866666666667}, \"9\": {\"effect\": -0.33245915174484253, \"value\": 50.0}, \"10\": {\"effect\": -0.014192258007824421, \"value\": 3.027430340557239}, \"11\": {\"effect\": -0.00029720563907176256, \"value\": 2.971867192491078}, \"12\": {\"effect\": -0.003310168394818902, \"value\": 2.9147368421053352}, \"13\": {\"effect\": 0.1760406494140625, \"value\": 125.0}, \"14\": {\"effect\": 0.23242834210395813, \"value\": 121.0}, \"15\": {\"effect\": 0.35969120264053345, \"value\": 116.0}, \"16\": {\"effect\": -0.002724159276112914, \"value\": 2.1345750873107585}, \"17\": {\"effect\": 5.975374369882047e-05, \"value\": 1.902147869431133}, \"18\": {\"effect\": -0.023055486381053925, \"value\": 1.690570430733462}, \"19\": {\"effect\": -0.0001633515057619661, \"value\": 156.7672131147604}, \"22\": {\"effect\": -0.035490792244672775, \"value\": 17.0}, \"23\": {\"effect\": -0.0073456959798932076, \"value\": 16.5}, \"24\": {\"effect\": 0.004628552123904228, \"value\": 15.9}, \"25\": {\"effect\": -0.0013248184695839882, \"value\": 105.0}, \"26\": {\"effect\": 0.017101820558309555, \"value\": 39.92857142857143}, \"27\": {\"effect\": -0.002449911320582032, \"value\": 0.0}, \"28\": {\"effect\": -0.0005843144608661532, \"value\": 0.8394965034964849}, \"29\": {\"effect\": -0.02016783319413662, \"value\": 0.5491992429882185}, \"30\": {\"effect\": -0.0006755489739589393, \"value\": 0.4401361796098823}, \"31\": {\"effect\": -0.04630254581570625, \"value\": 15.0}, \"32\": {\"effect\": -0.4360423684120178, \"value\": 14.909090909090908}, \"33\": {\"effect\": 0.023893289268016815, \"value\": 14.0}, \"35\": {\"effect\": 0.008740367367863655, \"value\": 285.0}, \"36\": {\"effect\": 0.10458068549633026, \"value\": 201.33333333333334}, \"37\": {\"effect\": 0.04544910043478012, \"value\": 135.0}, \"38\": {\"effect\": -0.0008896613726392388, \"value\": 15.0}, \"39\": {\"effect\": 0.12063665688037872, \"value\": 13.75}, \"40\": {\"effect\": 0.00661975983530283, \"value\": 13.0}, \"41\": {\"effect\": 0.054988909512758255, \"value\": 28.8}, \"42\": {\"effect\": 0.009601335972547531, \"value\": 28.600000000000005}, \"43\": {\"effect\": 0.01270697358995676, \"value\": 28.4}, \"44\": {\"effect\": 0.03676634281873703, \"value\": 126.0}, \"45\": {\"effect\": -0.04412369057536125, \"value\": 83.2948717948718}, \"46\": {\"effect\": -0.02091224677860737, \"value\": 38.0}, \"47\": {\"effect\": 0.010935152880847454, \"value\": 169.78722697055525}, \"48\": {\"effect\": 0.07119555026292801, \"value\": 3.0}, \"49\": {\"effect\": 0.002161608776077628, \"value\": 4.7}, \"50\": {\"effect\": -0.018613971769809723, \"value\": 4.475}, \"51\": {\"effect\": -0.0035641067661345005, \"value\": 4.3}, \"52\": {\"effect\": 0.004420153796672821, \"value\": 1.3}, \"53\": {\"effect\": -0.004342140629887581, \"value\": 1.3}, \"54\": {\"effect\": -0.01191473938524723, \"value\": 1.3}, \"55\": {\"effect\": -0.0024616303853690624, \"value\": 224.0}, \"56\": {\"effect\": -0.0030217093881219625, \"value\": 137.96428571428572}, \"57\": {\"effect\": -0.00017168419435620308, \"value\": 59.0}, \"58\": {\"effect\": 0.00011404213728383183, \"value\": 1.9}, \"59\": {\"effect\": -0.0038311630487442017, \"value\": 1.8666666666666665}, \"60\": {\"effect\": 0.0003080348833464086, \"value\": 1.8}, \"61\": {\"effect\": -0.0015688437270000577, \"value\": 93.0}, \"62\": {\"effect\": 0.013865702785551548, \"value\": 35.59016393442623}, \"63\": {\"effect\": 0.026082640513777733, \"value\": 16.0}, \"64\": {\"effect\": -0.029555637389421463, \"value\": 105.7}, \"65\": {\"effect\": 0.04036131128668785, \"value\": 57.01163934426229}, \"66\": {\"effect\": 0.0084436796605587, \"value\": 39.33}, \"67\": {\"effect\": -0.008862053044140339, \"value\": 138.0}, \"68\": {\"effect\": 0.10699904710054398, \"value\": 99.85245901639344}, \"69\": {\"effect\": 0.07613668590784073, \"value\": 80.0}, \"70\": {\"effect\": -0.016043920069932938, \"value\": 136.0}, \"71\": {\"effect\": 0.024480575695633888, \"value\": 133.75}, \"72\": {\"effect\": 0.027112770825624466, \"value\": 132.0}, \"73\": {\"effect\": 0.00031578552443534136, \"value\": 49.0}, \"74\": {\"effect\": -0.05964911729097366, \"value\": 46.0}, \"75\": {\"effect\": 0.001850628643296659, \"value\": 43.0}, \"76\": {\"effect\": 0.033628493547439575, \"value\": 197.0}, \"77\": {\"effect\": -0.007118337322026491, \"value\": 112.75}, \"78\": {\"effect\": 0.023759251460433006, \"value\": 55.0}, \"79\": {\"effect\": -0.023029478266835213, \"value\": 265.0}, \"80\": {\"effect\": -0.022236566990613937, \"value\": 265.0}, \"81\": {\"effect\": -0.00027235341258347034, \"value\": 265.0}, \"82\": {\"effect\": 0.010065346956253052, \"value\": 29.30063578564996}, \"83\": {\"effect\": 0.025287067517638206, \"value\": 19.660982232123246}, \"84\": {\"effect\": 0.010867207311093807, \"value\": 12.019981834695585}, \"85\": {\"effect\": 7.959705544635653e-05, \"value\": 97.64397321428217}, \"86\": {\"effect\": 0.006080451421439648, \"value\": 96.56494346757592}, \"87\": {\"effect\": -0.0013063573278486729, \"value\": 94.82779017857364}, \"88\": {\"effect\": -0.013612858019769192, \"value\": 157.0}, \"89\": {\"effect\": 0.0446954220533371, \"value\": 63.0}, \"90\": {\"effect\": 0.0021862236317247152, \"value\": 0.0}, \"91\": {\"effect\": 0.02950390987098217, \"value\": 37.1}, \"92\": {\"effect\": 0.12828756868839264, \"value\": 36.472727272727276}, \"93\": {\"effect\": 0.00458226352930069, \"value\": 35.8}, \"94\": {\"effect\": -0.0027472926303744316, \"value\": 8.427804878047949}, \"95\": {\"effect\": -0.00019499423797242343, \"value\": 6.968968641114796}, \"96\": {\"effect\": -0.0018354387721046805, \"value\": 5.584390243902261}, \"97\": {\"effect\": 0.0004085028194822371, \"value\": 2.68}, \"98\": {\"effect\": 0.011771509423851967, \"value\": 2.68}, \"99\": {\"effect\": 0.005126029718667269, \"value\": 2.68}, \"100\": {\"effect\": -0.03108924813568592, \"value\": 610.6469224826172}, \"101\": {\"effect\": -0.18848638236522675, \"value\": 134.0179374715217}, \"102\": {\"effect\": 0.008679813705384731, \"value\": 24.189363893896473}, \"103\": {\"effect\": -0.016945913434028625, \"value\": 16.3}, \"104\": {\"effect\": 0.059331025928258896, \"value\": 16.3}, \"105\": {\"effect\": 0.037610337138175964, \"value\": 16.3}, \"106\": {\"effect\": -0.06247904524207115, \"value\": 148.0}, \"107\": {\"effect\": -0.015751592814922333, \"value\": 144.54430379746836}, \"108\": {\"effect\": -0.0012796467635780573, \"value\": 144.5}, \"109\": {\"effect\": 0.006987635977566242, \"value\": 7.2}, \"110\": {\"effect\": -0.013073212467133999, \"value\": 7.1775}, \"111\": {\"effect\": 0.05154305323958397, \"value\": 7.16}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n",
       "    document.getElementById('i7OMV538L6FVPWSP0B8GO')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[1000,:], test_X.iloc[1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
